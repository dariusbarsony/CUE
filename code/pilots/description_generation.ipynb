{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import os\n",
    "import skimage\n",
    "import IPython.display\n",
    "import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import textwrap\n",
    "\n",
    "# load model, instantiate device\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model.eval()\n",
    "# obtain embeddings\n",
    "\n",
    "image = preprocess(Image.open(\"../data/archobjects_sample/vaasfragment.jpg\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize(['greek', 'greek vase fragment', 'greek vase']).to(device)\n",
    "# predict\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# images in skimage to use and their textual descriptions\n",
    "descriptions_dutch = {\n",
    "    \"man\": \"Sophokles. Origineel in Rome, Vaticaans Museum\",\n",
    "    \"zegelafdruk\": \"zegelafdruk; bustes vrouw en man>, buste met draperie; klei grijsbruin\",\n",
    "    \"buste\": \" bovendeel naakte vrouw, haar in scheiding, grote oorhangers, witte grondering; klei: lichtrood\",\n",
    "    \"vrouwofmeisje\": \"bovendeel staand meisje, chiton en himation, linkerhand aan himation op borst; hoofd bedekt met bolletjes-krullen; sporen witte grondering; klei rood\",\n",
    "    \"vaasfragment\": \"fragment; deel van een figuur die met naakte linkerarm, elleboog, op rots rust; torso, lichaam van naakte vrouw, iets vooroverbuigend naar rechts\",\n",
    "}\n",
    "\n",
    "descriptions = {\n",
    "    \"man\": \"Sophocles. Original in Rome, Vatican Museum\",\n",
    "    \"zegelafdruk\": \"seal impression; busts woman and man>, bust with drapery; clay gray brown\",\n",
    "    \"buste\": \"naked woman's upper part, hair parted, large earrings, white ground; clay: light red\",\n",
    "    \"vrouwofmeisje\": \"top part standing girl, chiton and himation, left hand to himation on breast; head covered with ball curls; traces of white ground; clay red\",\n",
    "    \"vaasfragment\": \"fragment; part of a figure resting on rock with naked left arm, elbow; torso, body of naked woman, bending slightly to the right\",\n",
    "}\n",
    "original_images = []\n",
    "images = []\n",
    "texts = []\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "filepath = '../data/archobjects_sample/'\n",
    "\n",
    "for filename in [filename for filename in os.listdir(filepath) if filename.endswith(\".png\") or filename.endswith(\".jpg\")]:\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    if name not in descriptions:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(os.path.join(filepath, filename)).convert(\"RGB\")\n",
    "  \n",
    "    plt.subplot(2, 4, len(images) + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"{filename}\\n \\n{textwrap.fill(descriptions[name], 40)}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    original_images.append(image)\n",
    "    images.append(preprocess(image))\n",
    "    texts.append(descriptions[name])\n",
    "\n",
    "plt.tight_layout()\n",
    "image_input = torch.tensor(np.stack(images))\n",
    "text_tokens = clip.tokenize([\"This is \" + desc for desc in texts])\n",
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_input).float()\n",
    "    text_features = model.encode_text(text_tokens).float()\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n",
    "count = len(descriptions)\n",
    "\n",
    "plt.figure(figsize=(20, 14))\n",
    "plt.imshow(similarity, vmin=0.1, vmax=0.3)\n",
    "# plt.colorbar()\n",
    "plt.yticks(range(count), [textwrap.fill(label, 40) for label in texts], fontsize=18)\n",
    "plt.xticks([])\n",
    "for i, image in enumerate(original_images):\n",
    "    plt.imshow(image, extent=(i - 0.5, i + 0.5, -1.6, -0.6), origin=\"lower\")\n",
    "for x in range(similarity.shape[1]):\n",
    "    for y in range(similarity.shape[0]):\n",
    "        plt.text(x, y, f\"{similarity[y, x]:.2f}\", ha=\"center\", va=\"center\", size=12)\n",
    "\n",
    "for side in [\"left\", \"top\", \"right\", \"bottom\"]:\n",
    "  plt.gca().spines[side].set_visible(False)\n",
    "\n",
    "plt.xlim([-0.5, count - 0.5])\n",
    "plt.ylim([count + 0.5, -2])\n",
    "\n",
    "plt.title(\"Cosine similarity between text and image features\", size=20)\n",
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "cifar100 = CIFAR100(os.path.expanduser(\"~/.cache\"), transform=preprocess, download=True)\n",
    "text_descriptions = [f\"This is a photo of a {label}\" for label in cifar100.classes]\n",
    "text_tokens = clip.tokenize(text_descriptions)\n",
    "with torch.no_grad():\n",
    "    text_features = model.encode_text(text_tokens).float()\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "top_probs, top_labels = text_probs.cpu().topk(5, dim=-1)\n",
    "plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i, image in enumerate(original_images):\n",
    "    plt.subplot(4, 4, 2 * i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(4, 4, 2 * i + 2)\n",
    "    y = np.arange(top_probs.shape[-1])\n",
    "    plt.grid()\n",
    "    plt.barh(y, top_probs[i])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.yticks(y, [cifar100.classes[index] for index in top_labels[i].numpy()])\n",
    "    plt.xlabel(\"probability\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
