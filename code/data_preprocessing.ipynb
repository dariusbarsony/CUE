{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exhibition catalogs\n",
    "extract text from: Sicily EN, Crossroads NL, crossroads EN, Eeuwig Egypte NL, Rome EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules \n",
    "import PyPDF2\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '../data/catalogs/'\n",
    "\n",
    "# filenames: \n",
    "ROME_EN = 'Rome_EN_LR_compleet'\n",
    "EGYPTE_NL = 'Eeuwig_Egypte_NL_LR'\n",
    "CROSSROADS_NL = 'CrossRoads_NEDERLANDS_LR_compleet'\n",
    "CROSSROADS_EN = 'CrossRoads_ENGELS_LR_compleet'\n",
    "SICILY_EN = 'sicily_en'\n",
    "\n",
    "books = [ROME_EN, EGYPTE_NL, CROSSROADS_EN, CROSSROADS_NL, SICILY_EN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PdfReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[429], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# writing the fields \u001b[39;00m\n\u001b[1;32m     11\u001b[0m csvwriter\u001b[38;5;241m.\u001b[39mwriterow(fields) \n\u001b[0;32m---> 13\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m(dirname \u001b[38;5;241m+\u001b[39m b \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pagei \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reader\u001b[38;5;241m.\u001b[39mpages)):\n\u001b[1;32m     15\u001b[0m     page \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mpages[pagei]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PdfReader' is not defined"
     ]
    }
   ],
   "source": [
    "fields = ['data']\n",
    "\n",
    "for b in books: \n",
    "    \n",
    "    with open('extract_' + b + '.csv', 'w') as csvfile:\n",
    "\n",
    "        # creating a csv writer object \n",
    "        csvwriter = csv.writer(csvfile) \n",
    "         \n",
    "        # writing the fields \n",
    "        csvwriter.writerow(fields) \n",
    "\n",
    "        reader = PdfReader(dirname + b + '.pdf')\n",
    "        for pagei in range(len(reader.pages)):\n",
    "            page = reader.pages[pagei]\n",
    "            csvwriter.writerow([page.extract_text()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "df_egypte = pd.read_csv('extract_' + EGYPTE_NL + '.csv')\n",
    "df_crossroads = pd.read_csv('extract_' + CROSSROADS_EN + '.csv')\n",
    "\n",
    "credits_egypte = df_egypte.iloc[91]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordcloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[433], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# code copied from: https://jingwen-z.github.io/data-viz-with-matplotlib-series9-word-cloud/\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mwordcloud\u001b[49m\u001b[38;5;241m.\u001b[39mWordCloud(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1280\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m853\u001b[39m, margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      3\u001b[0m                       colormap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgenerate([corpus][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(wordcloud, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wordcloud' is not defined"
     ]
    }
   ],
   "source": [
    "# code copied from: https://jingwen-z.github.io/data-viz-with-matplotlib-series9-word-cloud/\n",
    "wordcloud = wordcloud.WordCloud(width=1280, height=853, margin=0,\n",
    "                      colormap='Blues').generate([corpus][0])\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "# plt.savefig('descriptions_wordcloud.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expects dataframe as input\n",
    "def preprocess(book):\n",
    "    \n",
    "    df = pd.read_csv('extract_' + book + '.csv')\n",
    "    df = df.dropna()\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    corpus = ''\n",
    "\n",
    "    for i in range(len(df.index)):\n",
    "\n",
    "        # tokenize\n",
    "        query = tokenizer.tokenize(df['data'].iloc[i])\n",
    "\n",
    "        # filter stop words convert to lower\n",
    "        filtered_sentence = [w.lower() for w in query if not w.lower() in stop_words]\n",
    "\n",
    "        # filter digits\n",
    "        filtered_sentence = [w for w in filtered_sentence if not w.isdigit()]\n",
    "\n",
    "        df['data'].iloc[i] = \" \".join(filtered_sentence)\n",
    "        corpus += \" \".join(filtered_sentence)\n",
    "        \n",
    "    return df, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, corpus = preprocess(EGYPTE_NL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_egypte_nl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Egypte_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract apm numbers from eternal egypt credits page\n",
    "def extract_apm(credits_page):\n",
    "    \n",
    "    if type(credits_page) != str:\n",
    "        raise('invalid input')\n",
    "    \n",
    "    # tokenize input\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    credits = tokenizer.tokenize(credits_page)\n",
    "    \n",
    "    # find section within page with apm labels\n",
    "    credits = credits[credits.index('omslag'): credits.index('nederlands')]\n",
    "    credits = ' '.join(credits)\n",
    "    \n",
    "    # segment into; (blz), (page num), (apm references)\n",
    "    pages_apm_egypte = re.findall('(blz\\s)(\\d+)(.*?)blz', credits)\n",
    "    \n",
    "    # process regex extract \n",
    "    labels_egypte = []\n",
    "    \n",
    "    for _, p, apm in pages_apm_egypte:\n",
    "        apm_refs = re.findall('\\d{4,}', apm)     \n",
    "        apm_refs = ['0' + r if len(r) <= 4 else r for r in apm_refs]\n",
    "        labels_egypte += [(int(p), apm_refs)]\n",
    "    \n",
    "    return pd.DataFrame(labels_egypte, columns=['page', 'apm']).explode('apm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = extract_apm(credits_egypte['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pages(refs, book):\n",
    "    # create labels similar to index of df\n",
    "    mapping = create_mapping(book)[1:-2]\n",
    "    pages = list(refs['page'])\n",
    "    idx = cross_reference(pages, mapping)\n",
    "    \n",
    "    return df.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for egypte splitting up pages\n",
    "def create_mapping(df):\n",
    "    start = 2\n",
    "    mapping = []\n",
    "    mapping += [1]\n",
    "    \n",
    "    for i in range(1, len(df.index) - 1):\n",
    "        pages = [start, start + 1] \n",
    "        mapping += [pages]\n",
    "        start += 2\n",
    "    mapping += [start]\n",
    "    return mapping\n",
    "\n",
    "def cross_reference(pages, mapping):\n",
    "    idx = []\n",
    "    for p in pages:\n",
    "        counter = 1\n",
    "        for m in mapping:\n",
    "            if p in m:\n",
    "                idx.append(counter)\n",
    "            counter +=1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = list(refs['page'])\n",
    "mapping = create_mapping(df_egypte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = cross_reference(pages, mapping[1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_book = filter_pages(refs, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labels crossroads\n",
    "obtaining the apm numbers from the 'illustratie verantwoording'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apm(descr):\n",
    "    return re.findall('(?:APM)\\s*(\\d+)', descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_crossroads = ' 10 above (APM16324),  \\n13 (APM13822, APM9370),  \\n29 above (APM7855),  51 (APM9276, APM9278, APM9280),  52 (APM16772),  \\n66 (APM7468),  \\n67 (APM12995),  \\n69, 71 (APM7798),  \\n72 (APM16388),  73 (APM3830),  \\n74 (APM7798),  \\n103 below (APM12974), \\n146 (APM8471),  147 (APM8107),  \\n162 (APM7071),  163 left (APM09163),  \\n163 right (APM15589),  \\n176 above (APM16369), 180 (APM3831, APM10998)'\n",
    "page_numbers = [10, 13, 13, 29, 51, 51, 51, 52, 66, 67, 69, 72, 73, 74, 103, 146, 147, 162, 163, 163, 176, 180, 180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "references_crossroads = apm(credits_crossroads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_crossroads = [x + -2 for x in page_numbers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create labels and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels(df, idx, refs, outputfilename):\n",
    "    labels = np.zeros_like(df.index)\n",
    "    \n",
    "    mapping = zip(idx, refs)\n",
    "    \n",
    "    for pageid, apm in mapping:\n",
    "        labels[pageid] = apm\n",
    "        \n",
    "    np.savetxt(outputfilename, labels, delimiter=\",\")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_crossroads = labels(df_crossroads, page_numbers, references_crossroads, 'crossroads.csv')\n",
    "labels_egypte = labels(df_egypte, idx, list(refs.explode('apm')['apm']), 'egypt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1299147726.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[450], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"Inventory numbers Allard\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "\"Inventory numbers Allard\n",
    "Pierson Museum\n",
    "Cover: 14232\n",
    "p. 6: 16751\n",
    "p. 28: 3493\n",
    "p. 31: 3271\n",
    "p. 33: 7802\n",
    "p. 35: above 7164, below 7316\n",
    "p. 37: 7971\n",
    "p. 38: 9227\n",
    "p. 40: 16883\n",
    "p. 41: 16228\n",
    "p. 43: 13055\n",
    "p. 45: 1379\n",
    "p. 48: 13937\n",
    "p. 50: above 12378, below\n",
    "10167\n",
    "p. 52: 13825\n",
    "p. 53: 1627\n",
    "p. 55: 7347 and 7349\n",
    "p. 56: 7286\n",
    "p. 57: 7359 and 13963\n",
    "p. 59: 7326\n",
    "p. 61: 2907\n",
    "p. 62: 1786 (photo Restauratieatelier\n",
    "Restaura)\n",
    "p. 64: above 3239 and 2845,\n",
    "below 1785\n",
    "p. 65: 788\n",
    "p. 69: 1892\n",
    "p. 72: 8343\n",
    "p. 73: above 13946,\n",
    "below 15758\n",
    "p. 74: above 15369 and 15370\n",
    "p. 75: 14005\n",
    "p. 76: 6349\n",
    "p. 77: 12428\n",
    "p. 78: 7592\n",
    "p. 80: 15396\n",
    "p. 81: 8188\n",
    "p. 82: 3242 and 3243\n",
    "p. 84: above 9374, below 1774\n",
    "p. 85: 8180\n",
    "p. 86: 3269\n",
    "p. 87: 3422\n",
    "p. 92: 12\n",
    "p. 93 above 1606\n",
    "p. 95: 8552\n",
    "p. 96: 35\n",
    "p. 97: above 12417, below\n",
    "12534\n",
    "p. 100: above 7066, 8124, 8116,\n",
    "below 8117, 7065, 8120\n",
    "p. 101: 7974\n",
    "p. 102: 7757\n",
    "p. 103: 8133\n",
    "p. 104: left 7288, 7290, 7874\n",
    "and 8023, right 725\n",
    "p. 105: 7768\n",
    "p. 107: 8146.001-009\n",
    "p. 108: 8169\n",
    "p. 109: 16217\n",
    "p. 110: 16166\n",
    "p. 115: 9234\n",
    "p. 118: 1674\n",
    "p. 119: 15076\n",
    "p. 122: 1402\n",
    "p. 123: 8016\n",
    "p. 124: 7799\n",
    "p. 126: 8175\n",
    "p. 128: 7946\n",
    "p. 131: 11972\n",
    "p. 132: 1765\n",
    "p. 133: 15914\n",
    "p. 137: 5205, 5208, 5216, 5220,\n",
    "5222, 5230\n",
    "p. 139: 15927\n",
    "p. 140: 9894-9900, 10675\n",
    "p. 141: 9350\n",
    "p. 142: 8133\n",
    "p. 143: 7022\n",
    "p. 144: 6295, 6296, 7304,\n",
    "7308, 14165\n",
    "p. 145: 7001, 7003, 7004\n",
    "p. 146: 724\n",
    "p. 148: 1687\n",
    "p. 151: above 15746, below\n",
    "1722\n",
    "p. 153: 8363, 319, 1681, 6319,\n",
    "p. 156: 12.324\n",
    "p. 157: left 16618, right 12481\n",
    "p. 158: above 15689,\n",
    "below 15999\n",
    "p. 161: 451\n",
    "p. 162: 3579\n",
    "p. 163: 7163\n",
    "p. 164: 7310\n",
    "p. 165: 9224\n",
    "p. 167: 7379\n",
    "p. 174: 14.409\n",
    "p. 176: 5180\n",
    "p. 177: 16763\n",
    "p. 178-179: 10854\n",
    "p. 180: 10.854\n",
    "p. 181: 9241\n",
    "p. 182: 6287\n",
    "p. 183: 16882\n",
    "p. 185: 16604, 16607, 16612,\n",
    "16614, 16616, 16610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1808091653.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[451], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    Allard Pierson Museum\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Inventarisnummers\n",
    "Allard Pierson Museum\n",
    "omslag: 4076\n",
    "blz. 17: boven 196-1/2; onder\n",
    "4170-4173, 4222\n",
    "blz. 18: 4206, 4143, 4145\n",
    "blz. 21: 15290\n",
    "blz. 22: boven 4162, 4218, 4164, 4219;\n",
    "onder 3974/3863, 3972A\n",
    "blz. 23: 12637\n",
    "blz. 33: 12720, 15276, 3943\n",
    "blz. 34: boven 3858; onder 12676,\n",
    "12678\n",
    "blz. 35: boven 4044; onder 15999,\n",
    "16476\n",
    "blz. 37: 15302, 15301\n",
    "blz. 39: boven 7298; onder 4306\n",
    "blz. 40: 3635, 12683\n",
    "blz. 42: boven 8752/14021; onder\n",
    "Schriftmuseum Dortmond\n",
    "P. Amsterdam 22\n",
    "blz. 43: 9274, 15592\n",
    "blz. 46: 3933\n",
    "blz. 47: 8850\n",
    "blz. 48: 3400\n",
    "blz. 49: 16000\n",
    "blz. 51: 8539\n",
    "blz. 53: 12698\n",
    "blz. 54: 12647, 14238\n",
    "blz. 63: 15350\n",
    "blz. 64: 9237\n",
    "blz. 65: 8789\n",
    "blz. 69: 12978\n",
    "blz. 73: APM 9115\n",
    "blz. 75: 1387\n",
    "blz. 76: boven 3408, 360, 3799;\n",
    "onder 11960\n",
    "blz. 77: 12718, 8537\n",
    "blz. 78: 8851; Schriftmuseum\n",
    "Dortmond, no. 115\n",
    "blz. 79: boven 9114; onder 8875, 1676\n",
    "blz. 86: 16500\n",
    "blz. 87: boven 9223; onder 8811\n",
    "blz. 88: 13283a-j, 8800\n",
    "blz. 99: 391\n",
    "blz. 100: boven 8065; onder 13292\n",
    "blz. 102: 7774\n",
    "blz. 103: 12760, 4307, 15326\n",
    "blz. 104: 12977\n",
    "blz. 105: 9475, 9492, 9502\n",
    "blz. 106: 8562, 8563, 8417\n",
    "blz. 107: 8831\n",
    "blz. 108: 20\n",
    "blz. 109: 8837\n",
    "blz. 111: 13219\n",
    "blz. 115: 8795/6\n",
    "blz. 116: 7126\n",
    "blz. 117: 7772\n",
    "blz. 118: 6289\n",
    "blz. 119: 7993\n",
    "blz. 120: 8846\n",
    "blz. 124: 7216, 7238, 7272\n",
    "blz. 125: 13158\n",
    "blz. 129: 7758\n",
    "blz. 130: 7763\n",
    "blz. 131: 9369\n",
    "blz. 132: 8517\n",
    "blz. 133: 7796\n",
    "blz. 135: 14232\n",
    "blz. 136: 7860, 7861\n",
    "blz. 137: 9353\n",
    "blz. 138: 7874, 9227\n",
    "blz. 139: 7803\n",
    "blz. 141: 7766\n",
    "blz. 142: boven 7757; onder 7974\n",
    "blz. 143: 7761\n",
    "blz. 144: 8188\n",
    "blz. 145: 6286\n",
    "blz. 150: 12995, 14513\n",
    "blz. 152: boven 16750; onder 14510\n",
    "blz. 153: 8189\n",
    "blz. 159: 16385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cue",
   "language": "python",
   "name": "cue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
