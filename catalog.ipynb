{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of a pdf called cross culture which is a catalog of the allard pierson museum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "www.allardpiersonmuseum.nlCROSSROADS\n",
      "A runic graffito in the Hagia Sophia, a gilt Byzantine \n",
      "helmet in the grave of a Frankish nobleman, a trea­\n",
      "sure hidden from the Vikings in the Low Countries  containing an Arab dirham: these are just a few exam ­\n",
      "ples of the telling early ­medieval finds in this book. \n",
      "Late Antiquity and the Early Middle Ages are often \n",
      "viewed as a time of decline, chaos, invasions and  war. But there is another side to this period as well. \n",
      "There was a rich diversity of cultures in Europe —  \n",
      "from Longo  bards and Merovingians to Byzantines \n",
      "and Avars — and a lively exchange of goods and \n",
      "ideas, sometimes over great distances. The Vikings  \n",
      "set up a trade network that reached to Baghdad;  \n",
      "the Silk Road brought commodities to Europe, but also diplomatic missions, knowledge and ideas.  \n",
      "This is illustrated by the interludes in this book, the \n",
      "stories of ten travellers: pilgrims, scholars, diplomats, \n",
      "and an elephant.\n",
      "Despite the numerous conflicts, the period from  \n",
      "300 to 1000 AD was also one of growth, continuity \n",
      "and peaceful coexistence. From the late eighteenth \n",
      "century a romantic view of the Middle Ages arose, \n",
      "resulting in the Gothic Revival and the art of the  Pre ­Raphaelites. Nation states today happily refer  \n",
      "to the heroism of the Early Middle Ages, when king ­\n",
      "doms were born and present ­day Europe began to \n",
      "take shape. TRAVELLING \n",
      "THROUGH THE MIDDLE AGES\n",
      "TRAVELLING \n",
      "THROUGH THE \n",
      "MIDDLE AGES\n",
      "CROSS\n",
      "ROADS\n"
     ]
    }
   ],
   "source": [
    "# importing required modules \n",
    "import PyPDF2 \n",
    "    \n",
    "# creating a pdf file object \n",
    "pdfFileObj = open('data/CrossRoads_ENGELS_LR_compleet.pdf', 'rb') \n",
    "    \n",
    "# creating a pdf reader object \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "    \n",
    "# printing number of pages in pdf file \n",
    "print(pdfReader.numPages) \n",
    "    \n",
    "# creating a page object \n",
    "pageObj = pdfReader.getPage(0) \n",
    "    \n",
    "# extracting text from page \n",
    "print(pageObj.extractText()) \n",
    "    \n",
    "# closing the pdf file object \n",
    "pdfFileObj.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract text and obtain csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fields = ['text']\n",
    "filename = 'crossroads.csv'\n",
    "\n",
    "with open(filename, 'w') as csvfile:\n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "        \n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "\n",
    "    pdfFileObj = open('data/CrossRoads_ENGELS_LR_compleet.pdf', 'rb') \n",
    "    \n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "\n",
    "    for pagei in range(pdfReader.numPages):\n",
    "\n",
    "        # creating a page object \n",
    "        pageObj = pdfReader.getPage(pagei) \n",
    "            \n",
    "        csvwriter.writerow([pageObj.extractText()])\n",
    "            \n",
    "    # closing the pdf file object \n",
    "    pdfFileObj.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename='crossroads.csv'\n",
    "\n",
    "df = pd.read_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.allardpiersonmuseum.nlCROSSROADS\\nA runic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.allardpiersonmuseum.nlCROSSROADS\\nA runic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Travelling through the Middle Ages, \\nAD 300–1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This joint publication by the Allard Pierson M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDITORIAL BOARD\\nMaria Bormpoudaki\\nMarieke va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>206 CROSSROADS INFORMATIONKianoosh Rezania is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>207 AUTHORS’ BIOGRAPHIESILLUSTRATION \\nCREDITS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>COLOPHONLandesamt für Kultur und  \\nDenkmalpfl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>www.allardpiersonmuseum.nlCROSSROADS\\nA runic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>www.allardpiersonmuseum.nlCROSSROADS\\nA runic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    www.allardpiersonmuseum.nlCROSSROADS\\nA runic ...\n",
       "1    www.allardpiersonmuseum.nlCROSSROADS\\nA runic ...\n",
       "2    Travelling through the Middle Ages, \\nAD 300–1...\n",
       "3    This joint publication by the Allard Pierson M...\n",
       "4    EDITORIAL BOARD\\nMaria Bormpoudaki\\nMarieke va...\n",
       "..                                                 ...\n",
       "207  206 CROSSROADS INFORMATIONKianoosh Rezania is ...\n",
       "208  207 AUTHORS’ BIOGRAPHIESILLUSTRATION \\nCREDITS...\n",
       "209  COLOPHONLandesamt für Kultur und  \\nDenkmalpfl...\n",
       "210  www.allardpiersonmuseum.nlCROSSROADS\\nA runic ...\n",
       "211  www.allardpiersonmuseum.nlCROSSROADS\\nA runic ...\n",
       "\n",
       "[212 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/dariu/Documents/THESIS/CUE/catalog.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/dariu/Documents/THESIS/CUE/catalog.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m img2 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img2, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/dariu/Documents/THESIS/CUE/catalog.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#sift\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/dariu/Documents/THESIS/CUE/catalog.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m sift \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mxfeatures2d\u001b[39m.\u001b[39mSIFT_create()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/dariu/Documents/THESIS/CUE/catalog.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m keypoints_1, descriptors_1 \u001b[39m=\u001b[39m sift\u001b[39m.\u001b[39mdetectAndCompute(img1,\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/dariu/Documents/THESIS/CUE/catalog.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m keypoints_2, descriptors_2 \u001b[39m=\u001b[39m sift\u001b[39m.\u001b[39mdetectAndCompute(img2,\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read images\n",
    "img1 = cv2.imread('images/img-22.png')  \n",
    "img2 = cv2.imread('data/example.jpg') \n",
    "\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#sift\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "keypoints_1, descriptors_1 = sift.detectAndCompute(img1,None)\n",
    "keypoints_2, descriptors_2 = sift.detectAndCompute(img2,None)\n",
    "\n",
    "#feature matching\n",
    "bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "\n",
    "matches = bf.match(descriptors_1,descriptors_2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "img3 = cv2.drawMatches(img1, keypoints_1, img2, keypoints_2, matches[:50], img2, flags=2)\n",
    "plt.imshow(img3),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1.jpg is more similar to test.jpg as compare to data2.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "  \n",
    "     \n",
    "# test image\n",
    "image = cv2.imread('data/example.jpg')  \n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "histogram = cv2.calcHist([gray_image], [0],\n",
    "                         None, [256], [0, 256])\n",
    "  \n",
    "# data1 image\n",
    "image = cv2.imread('images/img-22.png')\n",
    "gray_image1 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "histogram1 = cv2.calcHist([gray_image1], [0],\n",
    "                          None, [256], [0, 256])\n",
    "  \n",
    "# data2 image\n",
    "image = cv2.imread('images/img-26.png')\n",
    "gray_image2 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "histogram2 = cv2.calcHist([gray_image2], [0],\n",
    "                          None, [256], [0, 256])\n",
    "  \n",
    "  \n",
    "c1, c2 = 0, 0\n",
    "  \n",
    "# Euclidean Distance between data1 and test\n",
    "i = 0\n",
    "while i<len(histogram) and i<len(histogram1):\n",
    "    c1+=(histogram[i]-histogram1[i])**2\n",
    "    i+= 1\n",
    "c1 = c1**(1 / 2)\n",
    "  \n",
    " \n",
    "# Euclidean Distance between data2 and test\n",
    "i = 0\n",
    "while i<len(histogram) and i<len(histogram2):\n",
    "    c2+=(histogram[i]-histogram2[i])**2\n",
    "    i+= 1\n",
    "c2 = c2**(1 / 2)\n",
    "  \n",
    "if(c1<c2):\n",
    "    print(\"data1.jpg is more similar to test.jpg as compare to data2.jpg\")\n",
    "else:\n",
    "    print(\"data2.jpg is more similar to test.jpg as compare to data1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means image clustering\n",
    "code from: https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 15:35:34.400261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 15:35:37.104992: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 15:35:37.107213: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 0s 288ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "features extracted\n",
      "applying pca\n",
      "pca done\n",
      "starting clustering\n"
     ]
    }
   ],
   "source": [
    "# for loading/processing the images  \n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "path = r\"/mnt/c/Users/dariu/Documents/THESIS/CUE/images\"\n",
    "# change the working directory to the path where the images are located\n",
    "os.chdir(path)\n",
    "\n",
    "# this list holds all the image filename\n",
    "flowers = []\n",
    "\n",
    "# creates a ScandirIterator aliased as files\n",
    "with os.scandir(path) as files:\n",
    "  # loops through each file in the directory\n",
    "    for file in files:\n",
    "        if file.name.endswith('.png'):\n",
    "          # adds only the image files to the flowers list\n",
    "            flowers.append(file.name)\n",
    "            \n",
    "            \n",
    "            \n",
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
    "\n",
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    img = np.array(img) \n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features\n",
    "   \n",
    "data = {}\n",
    "p = r\"data/clusters\"\n",
    "\n",
    "# lop through each image in the dataset\n",
    "for flower in flowers:\n",
    "    # try to extract the features and update the dictionary\n",
    "    try:\n",
    "        feat = extract_features(flower,model)\n",
    "        data[flower] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    except:\n",
    "        with open(p,'wb') as file:\n",
    "            pickle.dump(data,file)\n",
    "          \n",
    "print('features extracted')\n",
    "\n",
    "# get a list of the filenames\n",
    "filenames = np.array(list(data.keys()))\n",
    "\n",
    "# get a list of just the features\n",
    "feat = np.array(list(data.values()))\n",
    "\n",
    "# reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n",
    "\n",
    "# get the unique labels (from the flower_labels.csv)\n",
    "\n",
    "# no fixed number of cluster available. \n",
    "\n",
    "# df = pd.read_csv('flower_labels.csv')\n",
    "# label = df['label'].tolist()\n",
    "# unique_labels = list(set(label))\n",
    "\n",
    "print('applying pca')\n",
    "\n",
    "# reduce the amount of dimensions in the feature vector\n",
    "pca = PCA(n_components=15, random_state=22)\n",
    "pca.fit(feat)\n",
    "x = pca.transform(feat)\n",
    "\n",
    "print('pca done')\n",
    "print('starting clustering')\n",
    "# cluster feature vectors\n",
    "kmeans = KMeans(n_clusters=4, random_state=22, n_init=3, max_iter=100)\n",
    "kmeans.fit(x)\n",
    "print('clustering done')\n",
    "\n",
    "# holds the cluster id and the images { id: [images] }\n",
    "groups = {}\n",
    "for file, cluster in zip(filenames,kmeans.labels_):\n",
    "    if cluster not in groups.keys():\n",
    "        groups[cluster] = []\n",
    "        groups[cluster].append(file)\n",
    "    else:\n",
    "        groups[cluster].append(file)\n",
    "\n",
    "# function that lets you view a cluster (based on identifier)        \n",
    "def view_cluster(cluster):\n",
    "    plt.figure(figsize = (25,25))\n",
    "    # gets the list of filenames for a cluster\n",
    "    files = groups[cluster]\n",
    "    # only allow up to 30 images to be shown at a time\n",
    "    if len(files) > 30:\n",
    "        print(f\"Clipping cluster size from {len(files)} to 30\")\n",
    "        files = files[:29]\n",
    "    # plot each image in the cluster\n",
    "    for index, file in enumerate(files):\n",
    "        plt.subplot(10,10,index+1)\n",
    "        img = load_img(file)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "   \n",
    "# this is just incase you want to see which value for k might be the best \n",
    "sse = []\n",
    "list_k = list(range(3, 50))\n",
    "\n",
    "for k in list_k:\n",
    "    km = KMeans(n_clusters=k, random_state=22)\n",
    "    km.fit(x)\n",
    "    \n",
    "    sse.append(km.inertia_)\n",
    "\n",
    "# Plot sse against k\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse)\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cue",
   "language": "python",
   "name": "cue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
